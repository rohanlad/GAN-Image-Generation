{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWzm28ApsH34"
      },
      "outputs": [],
      "source": [
        "# CODE CITATIONS: \n",
        "# https://github.com/pytorch/tutorials/blob/master/beginner_source/dcgan_faces_tutorial.py\n",
        "# https://discuss.pytorch.org/t/help-regarding-slerp-function-for-generative-model-sampling/32475\n",
        "\n",
        "# imports\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# hyperparameters\n",
        "batch_size  = 64\n",
        "n_channels  = 3\n",
        "dataset = 'stl10'\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "g_feature_map_size = 64\n",
        "d_feature_map_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8agbSUz4tDqi",
        "outputId": "0cadf025-f561-42f0-dbda-d749a163d815"
      },
      "outputs": [],
      "source": [
        "# helper function to make getting another batch of data easier\n",
        "def cycle(iterable):\n",
        "    while True:\n",
        "        for x in iterable:\n",
        "            yield x\n",
        "\n",
        "if dataset == 'stl10':\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        torchvision.datasets.STL10('drive/My Drive/training/stl10', split='train+unlabeled', download=True, transform=torchvision.transforms.Compose([\n",
        "            torchvision.transforms.Resize(64),\n",
        "            torchvision.transforms.CenterCrop(64),                                                                                                                                              \n",
        "            torchvision.transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ])),\n",
        "    shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "    train_iterator = iter(cycle(train_loader))\n",
        "    class_names = ['airplane', 'bird', 'car', 'cat', 'deer', 'dog', 'horse', 'monkey', 'ship', 'truck'] # these are slightly different to CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "I8bFyoaiwWXj",
        "outputId": "45c44bbd-d4ea-4b77-b7dc-03d184ec3cbb"
      },
      "outputs": [],
      "source": [
        "# let's view some of the training data\n",
        "plt.rcParams['figure.dpi'] = 175\n",
        "x,t = next(train_iterator)\n",
        "x,t = x.to(device), t.to(device)\n",
        "plt.grid(False)\n",
        "plt.imshow(torchvision.utils.make_grid(x, normalize=True).cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiwVC9YnvJ-g",
        "outputId": "3236d621-158f-4449-f5b7-c15e616b196b"
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "# define the model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_size=100):\n",
        "        super(Generator, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.ConvTranspose2d(latent_size, g_feature_map_size * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(g_feature_map_size * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(g_feature_map_size * 8, g_feature_map_size * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(g_feature_map_size * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(g_feature_map_size * 4, g_feature_map_size * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(g_feature_map_size * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(g_feature_map_size * 2, g_feature_map_size, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(g_feature_map_size),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(g_feature_map_size, n_channels, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.layer = nn.Sequential(  \n",
        "            nn.Conv2d(n_channels, d_feature_map_size, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),     \n",
        "            nn.Conv2d(d_feature_map_size, d_feature_map_size * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(d_feature_map_size * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),  \n",
        "            nn.Conv2d(d_feature_map_size * 2, d_feature_map_size * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(d_feature_map_size * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),  \n",
        "            nn.Conv2d(d_feature_map_size * 4, d_feature_map_size * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(d_feature_map_size * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(d_feature_map_size * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "G.apply(weights_init)\n",
        "D.apply(weights_init)\n",
        "\n",
        "print(f'> Number of generator parameters {len(torch.nn.utils.parameters_to_vector(G.parameters()))}')\n",
        "print(f'> Number of discriminator parameters {len(torch.nn.utils.parameters_to_vector(D.parameters()))}')\n",
        "\n",
        "# initialise the optimiser\n",
        "optimiser_G = torch.optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimiser_D = torch.optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "bce_loss = nn.BCELoss()\n",
        "epoch = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyJ07lY_vVna"
      },
      "outputs": [],
      "source": [
        "# training loop\n",
        "while (epoch<300):\n",
        "\n",
        "    # array(s) for the performance measures\n",
        "    gen_loss_arr = np.zeros(0)\n",
        "    dis_loss_arr = np.zeros(0)\n",
        "\n",
        "   \n",
        "    # iterate over some of the train dateset\n",
        "    for i in range(821):\n",
        "        \n",
        "        # sample x from the dataset\n",
        "        x,t = next(train_iterator)\n",
        "        x,t = x.to(device), t.to(device)\n",
        "\n",
        "        # train discriminator\n",
        "        g = G(torch.randn(x.size(0), 100, 1, 1).to(device))\n",
        "        D.zero_grad()\n",
        "        l_r = bce_loss(D(x).view(-1), torch.full((x.size(0),), 1., dtype=torch.float).to(device))\n",
        "        l_f = bce_loss(D(g.detach()).view(-1), torch.full((x.size(0),), 0., dtype=torch.float).to(device))\n",
        "        l_r.backward()\n",
        "        l_f.backward()\n",
        "        loss_d = (l_r + l_f)\n",
        "        optimiser_D.step()\n",
        "\n",
        "        # train generator\n",
        "        G.zero_grad()\n",
        "        loss_g = bce_loss(D(g).view(-1), torch.full((x.size(0),), 1., dtype=torch.float).to(device))\n",
        "        loss_g.backward()\n",
        "        optimiser_G.step()\n",
        "\n",
        "        # collect stats\n",
        "        gen_loss_arr = np.append(gen_loss_arr, loss_g.item())\n",
        "        dis_loss_arr = np.append(dis_loss_arr, loss_d.item())\n",
        "\n",
        "    # plot some examples\n",
        "    G.eval()\n",
        "    rand_noise = torch.randn(x.size(0), 100, 1, 1).to(device)\n",
        "    g = G(rand_noise)\n",
        "    print('loss d: {:.3f}, loss g: {:.3f}'.format(gen_loss_arr.mean(), dis_loss_arr.mean()))\n",
        "    plt.grid(False)\n",
        "    plt.imshow(torchvision.utils.make_grid(g, normalize=True).cpu().data.clamp(0,1).permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "    plt.show()\n",
        "    plt.pause(0.0001)\n",
        "    G.train()\n",
        "\n",
        "    epoch = epoch+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "xoL3Ysn9_2xa",
        "outputId": "728972d8-da09-45c0-8778-1391b6b997e1"
      },
      "outputs": [],
      "source": [
        "# Show a batch of data\n",
        "plt.rcParams['figure.dpi'] = 175\n",
        "plt.grid(False)\n",
        "plt.imshow(torchvision.utils.make_grid(g, normalize=True).cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "EyHzVIJwzl9Q",
        "outputId": "56440b18-18b3-4a39-f82d-d0d5d17ac28b"
      },
      "outputs": [],
      "source": [
        "# now show some interpolations\n",
        "def slerp(low, high, val):\n",
        "    low_norm = low/torch.norm(low, dim=1, keepdim=True)\n",
        "    high_norm = high/torch.norm(high, dim=1, keepdim=True)\n",
        "    omega = torch.acos((low_norm*high_norm).sum(1)).view(batch_size,1,1,1)\n",
        "    so = torch.sin(omega)\n",
        "    a = (torch.sin((1-val)*omega)/so)\n",
        "    a = a * low\n",
        "    b = (torch.sin(val*omega)/so) * high\n",
        "    res = a + b\n",
        "    return res\n",
        "\n",
        "col_size = int(np.sqrt(batch_size))\n",
        "z0 = rand_noise[0:col_size].repeat(col_size,1,1,1) # z for top row\n",
        "z1 = rand_noise[batch_size-col_size:].repeat(col_size,1,1,1) # z for bottom row\n",
        "t = torch.linspace(0,1,col_size).unsqueeze(1).repeat(1,col_size).view(batch_size,1,1,1).to(device)\n",
        "z_point = slerp(z0, z1, t)\n",
        "\n",
        "slerp_g = G(z_point) # sample the model at the resulting interpolated latents\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 175\n",
        "plt.grid(False)\n",
        "plt.imshow(torchvision.utils.make_grid(slerp_g, normalize=True).cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "part1-model-code",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
